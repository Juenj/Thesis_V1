{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from libs.InteractivePitchUI import *\n",
    "from libs.data_manipulation import *\n",
    "from libs.dim_reduction import *\n",
    "from libs.feature_generation import *\n",
    "from libs.clustering import *\n",
    "from libs.convex_hull import *\n",
    "from libs.alpha_shape import *\n",
    "from libs.weight_generator import *\n",
    "from libs.similar_movement import *\n",
    "from libs.Video_Player import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time [s]_team', 'half_team', 'minute_team', 'Period_team', 'home_6_x',\n",
      "       'home_6_y', 'home_18_x', 'home_18_y', 'home_1_x', 'home_1_y',\n",
      "       'home_10_x', 'home_10_y', 'home_3_x', 'home_3_y', 'home_2_x',\n",
      "       'home_2_y', 'home_19_x', 'home_19_y', 'home_21_x', 'home_21_y',\n",
      "       'home_9_x', 'home_9_y', 'home_17_x', 'home_17_y', 'home_23_x',\n",
      "       'home_23_y', 'home_20_x', 'home_20_y', 'home_15_x', 'home_15_y',\n",
      "       'home_8_x', 'home_8_y', 'home_5_x', 'home_5_y', 'home_12_x',\n",
      "       'home_12_y', 'ball_z_team', 'Time [s]', 'half', 'minute', 'Period',\n",
      "       'away_10_x', 'away_10_y', 'away_2_x', 'away_2_y', 'away_17_x',\n",
      "       'away_17_y', 'away_22_x', 'away_22_y', 'away_9_x', 'away_9_y',\n",
      "       'away_1_x', 'away_1_y', 'away_20_x', 'away_20_y', 'away_21_x',\n",
      "       'away_21_y', 'away_11_x', 'away_11_y', 'away_13_x', 'away_13_y',\n",
      "       'away_6_x', 'away_6_y', 'away_7_x', 'away_7_y', 'away_5_x', 'away_5_y',\n",
      "       'away_14_x', 'away_14_y', 'away_23_x', 'away_23_y', 'away_19_x',\n",
      "       'away_19_y', 'ball_x', 'ball_y', 'ball_z', 'match_name', 'home_14_x',\n",
      "       'home_14_y', 'home_11_x', 'home_11_y', 'away_8_x', 'away_8_y',\n",
      "       'away_12_x', 'away_12_y', 'away_4_x', 'away_4_y', 'away_16_x',\n",
      "       'away_16_y', 'away_25_x', 'away_25_y', 'home_26_x', 'home_26_y',\n",
      "       'away_3_x', 'away_3_y', 'away_15_x', 'away_15_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "matches = compile_team_tracking_data_with_labels(\"../data/H_EURO2024GERMANY\", \"Denmark\", \"../data/Labelled_ground_truths.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_one_match(matches,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"match_name\"] == \"Denmark_England\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_control = lambda x:1\n",
    "func_inverse = lambda x: 20/x\n",
    "func_linear = lambda x: 200-x\n",
    "func_exp = lambda x: np.exp(-x/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Missing', 'run-into-space', 'breakthrough-wb',\n",
       "       'breakthrough-space', 'breakthrough-even'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/DBU/lib/python3.10/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/DBU/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/DBU/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 102\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# Return the dictionary with recommendations\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m recommendations_dict\n\u001b[0;32m--> 102\u001b[0m reccomendations_dict \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_situations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mprocess_situations\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      6\u001b[0m recommendations_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Step 2: Extract relevant rows (all rows with a label not equal to \"Missing\")\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m labeled_rows \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m relevant_indices \u001b[38;5;241m=\u001b[39m labeled_rows\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(relevant_indices)\n",
      "File \u001b[0;32m~/anaconda3/envs/DBU/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/DBU/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Label'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def process_situations(df):\n",
    "    # Dictionary to store recommendations\n",
    "    recommendations_dict = {}\n",
    "\n",
    "    # Step 2: Extract relevant rows (all rows with a label not equal to \"Missing\")\n",
    "    labeled_rows = df[df['Label'] != \"Missing\"]\n",
    "    relevant_indices = labeled_rows.index.tolist()\n",
    "    print(relevant_indices)\n",
    "    # Step 2: Process each relevant index\n",
    "    # Step 2: Process each relevant index\n",
    "    for relevant_index in relevant_indices:\n",
    "        # Step 3: Apply Wasserstein distance for various functions upfront\n",
    "        finished_indices_control = most_similar_with_wasserstein(relevant_index, df, func_control)\n",
    "        finished_indices_linear = most_similar_with_wasserstein(relevant_index, df, func_linear)\n",
    "        finished_indices_inverse = most_similar_with_wasserstein(relevant_index, df, func_inverse)\n",
    "        finished_indices_exp = most_similar_with_wasserstein(relevant_index, df, func_exp)\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        finished_indices_control = np.array(finished_indices_control)\n",
    "        finished_indices_exp = np.array(finished_indices_exp)\n",
    "        finished_indices_linear = np.array(finished_indices_linear)\n",
    "        finished_indices_inverse = np.array(finished_indices_inverse)\n",
    "\n",
    "        # Step 4: Filter indices based on the time window (Â±480 seconds)\n",
    "        time_window_filter = lambda indices: indices[\n",
    "            (indices > relevant_index + 480) | \n",
    "            (indices < relevant_index - 480)\n",
    "        ]\n",
    "\n",
    "        finished_indices_control = time_window_filter(finished_indices_control)[:100]\n",
    "        finished_indices_exp = time_window_filter(finished_indices_exp)[:100]\n",
    "        finished_indices_linear = time_window_filter(finished_indices_linear)[:100]\n",
    "        finished_indices_inverse = time_window_filter(finished_indices_inverse)[:100]\n",
    "\n",
    "        # Combine recommendations into a dictionary for separate processing\n",
    "        wasserstein_recommendations = {\n",
    "            \"Control\": finished_indices_control,\n",
    "            \"Exp\": finished_indices_exp,\n",
    "            \"Linear\": finished_indices_linear,\n",
    "            \"Inverse\": finished_indices_inverse\n",
    "        }\n",
    "        # Create the folder based on the label\n",
    "        # Step 6: Prepare the result DataFrame for this function set\n",
    "        label = df.loc[relevant_index, 'Label']  # Get the label for the situation\n",
    "        match_name = df.loc[relevant_index, 'match_name']\n",
    "        time_of_situation = str(datetime.timedelta(seconds=df.loc[relevant_index, 'Time [s]']))\n",
    "\n",
    "        folder_name = f\"{label}_{match_name}_{time_of_situation}\"\n",
    "        generate_folder(folder_name)\n",
    "\n",
    "        # Save the time and match_name to a text file\n",
    "        with open(f\"{folder_name}/situation_info.txt\", \"w\") as f:\n",
    "                f.write(f\"Match Name: {match_name}\\n\")\n",
    "                f.write(f\"Time of Situation: {time_of_situation}\\n\")\n",
    "\n",
    "        # Step 5: Process each set of indices separately\n",
    "        for func_name, indices_set in wasserstein_recommendations.items():\n",
    "            print(indices_set, func_name)\n",
    "            if len(indices_set) == 0:\n",
    "                continue  # Skip if no indices in this set\n",
    "\n",
    "            # Step 5.1: Compute similar movements for the current set\n",
    "            similar_movement = find_similar_movement_entire_team(df, relevant_index, indices_set,ball_weight=0.9)\n",
    "            similar_movement_ranked = sorted(similar_movement, key=lambda x: x[0])\n",
    "\n",
    "            # Step 5.2: Select indices, ensuring no two are within 100 places of each other\n",
    "            selected_indices = []\n",
    "            for _, index in similar_movement_ranked:\n",
    "                if all(abs(index - selected) > 100 for selected in selected_indices):\n",
    "                    selected_indices.append(index)\n",
    "                if len(selected_indices) == 10:  # Stop once we have 10 indices\n",
    "                    break\n",
    "\n",
    "            new_df = df.loc[selected_indices[:10]]\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            # Generate the result DataFrame\n",
    "            result_df = new_df[[\"match_name\", \"Time [s]\", \"half_team\"]]\n",
    "            result_df[\"Time Min\"] = result_df[\"Time [s]\"].apply(lambda x: str(datetime.timedelta(seconds=x)))\n",
    "\n",
    "            # Save the ground truth CSV for this function set\n",
    "            result_df.to_csv(f\"{folder_name}/{folder_name}_{func_name}_ground_truth.csv\")\n",
    "\n",
    "            # Shuffle and save the ordering truth CSV for this function set\n",
    "            result_df.sample(frac=1).to_csv(f\"{folder_name}/{folder_name}_{func_name}_for_ordering_truth.csv\")\n",
    "\n",
    "            # Store the recommendations in the dictionary\n",
    "            recommendations_dict[relevant_index] = recommendations_dict.get(relevant_index, {})\n",
    "            recommendations_dict[relevant_index][func_name] = selected_indices[:10]\n",
    "\n",
    "    # Return the dictionary with recommendations\n",
    "    return recommendations_dict\n",
    "\n",
    "    \n",
    "\n",
    "reccomendations_dict = process_situations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reccomendations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Pause Button\n",
      "Creating Play Button\n",
      "Creating Next Button\n",
      "Creating Previous Button\n",
      "Creating Close Button\n",
      "Creating Time Label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0000799e1c004e90] gles2 gl: Initialized libplacebo v4.192.1 (API v192)\n",
      "libva info: VA-API version 1.18.0\n",
      "libva error: vaGetDriverNameByIndex() failed with unknown libva error, driver_name = (null)\n",
      "[0000799e1c004e90] glconv_vaapi_x11 gl error: vaInitialize: unknown libva error\n",
      "libva info: VA-API version 1.18.0\n",
      "libva info: Trying to open /home/martinaguayo/anaconda3/envs/DBU/lib/dri/nvidia_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[0000799e1c004e90] glconv_vaapi_drm gl error: vaInitialize: unknown libva error\n",
      "libva info: VA-API version 1.18.0\n",
      "libva info: Trying to open /home/martinaguayo/anaconda3/envs/DBU/lib/dri/simpledrm_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[0000799e1c004e90] glconv_vaapi_drm gl error: vaInitialize: unknown libva error\n",
      "libva info: VA-API version 1.18.0\n",
      "libva info: Trying to open /home/martinaguayo/anaconda3/envs/DBU/lib/dri/nvidia_drv_video.so\n",
      "libva info: va_openDriver() returns -1\n",
      "[0000799e1c004e90] glconv_vaapi_drm gl error: vaInitialize: unknown libva error\n",
      "[0000799e1c004e90] gl gl: Initialized libplacebo v4.192.1 (API v192)\n",
      "[0000799ddd4c9670] avcodec decoder: Using NVIDIA VDPAU Driver Shared Library  550.54.14  Thu Feb 22 01:24:07 UTC 2024 for hardware decoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Time: 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"133720779761536update_time_label\"\n",
      "    while executing\n",
      "\"133720779761536update_time_label\"\n",
      "    (\"after\" script)\n",
      "[0000799ddd4c9670] main decoder error: Timestamp conversion failed (delay 1000000, buffering 100000, bound 9000000)\n",
      "[0000799ddd4c9670] main decoder error: Could not convert timestamp 17825698447 for FFmpeg\n",
      "[0000799ddd4c9670] main decoder error: Timestamp conversion failed (delay 1000000, buffering 100000, bound 9000000)\n",
      "[0000799ddd4c9670] main decoder error: Could not convert timestamp 20104568230 for FFmpeg\n",
      "[0000799ddd4c9670] main decoder error: Timestamp conversion failed (delay 1000000, buffering 100000, bound 9000000)\n",
      "[0000799ddd4c9670] main decoder error: Could not convert timestamp 17445565633 for FFmpeg\n",
      "[0000799ddd4c9670] main decoder error: Timestamp conversion failed (delay 1000000, buffering 100000, bound 9000000)\n",
      "[0000799ddd4c9670] main decoder error: Could not convert timestamp 17344750679 for FFmpeg\n",
      "[0000799ddd4c9670] main decoder error: Timestamp conversion failed (delay 1000000, buffering 100000, bound 9000000)\n",
      "[0000799ddd4c9670] main decoder error: Could not convert timestamp 17871755064 for FFmpeg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<libs.Video_Player.VideoPlayer at 0x799e3a4fada0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"breakthrough-space_Denmark_England_0:25:40/breakthrough-space_Denmark_England_0:25:40_Control_for_ordering_truth.csv\")\n",
    "\n",
    "indices_1 = df[[\"Time [s]\",\"Time Min\"]].to_numpy()\n",
    "\n",
    "\n",
    "VideoPlayer(\"3-2024-2036178-Denmark_England.mp4\",8,indices_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DBU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
